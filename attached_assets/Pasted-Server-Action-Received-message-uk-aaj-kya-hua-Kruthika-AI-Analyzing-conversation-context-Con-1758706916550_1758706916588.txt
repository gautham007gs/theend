Server Action: Received message: uk aaj kya hua
Kruthika AI: Analyzing conversation context...
Conversation context: normal_chat
Vertex AI: Starting optimized generateAIResponse...
User message length: 14
System prompt provided: true
Token Optimization: Selected gemini-2.0-flash-001 for conversation task
Token Optimization: Using short config, max tokens: 100
Token Optimization: Input tokens optimized by -8 chars (0% cost reduction)
Vertex AI: Sending optimized request to model...
Vertex AI: Received response from model
Token Optimization: Cached response for message: uk aaj kya hua...
Vertex AI: Successfully generated optimized response, length: 61
Kruthika AI: Generated contextual response: arre kuch nahi
Server Action: Generated enhanced response: arre kuch nahi
Server Action: New mood: naturally_responding
 POST /maya-chat 200 in 930ms
Server Action: Received message: aaj mai raste mai gir gaya tha , bhot chot lagi hai yarr
Kruthika AI: Analyzing conversation context...
Conversation context: normal_chat
Vertex AI: Starting optimized generateAIResponse...
User message length: 56
System prompt provided: true
Token Optimization: Selected gemini-2.0-flash-001 for conversation task
Token Optimization: Using normal config, max tokens: 300
Token Optimization: Input tokens optimized by -8 chars (0% cost reduction)
Vertex AI: Sending optimized request to model...
Vertex AI: Received response from model
Token Optimization: Cached response for message: aaj mai raste mai gir gaya tha...
Vertex AI: Successfully generated optimized response, length: 95
Kruthika AI: Generated contextual response: arre omg kya hua
Server Action: Generated enhanced response: arre omg kya hua
Server Action: New mood: naturally_responding
 POST /maya-chat 200 in 859ms
Server Action: Received message: ek gaadi ne aakr mereko thok diya yaar
Kruthika AI: Analyzing conversation context...
Conversation context: normal_chat
Vertex AI: Starting optimized generateAIResponse...
User message length: 38
System prompt provided: true
Token Optimization: Selected gemini-2.0-flash-001 for conversation task
Token Optimization: Using normal config, max tokens: 300
Token Optimization: Input tokens optimized by -8 chars (0% cost reduction)
Vertex AI: Sending optimized request to model...
Vertex AI: Received response from model
Token Optimization: Cached response for message: ek gaadi ne aakr mereko thok d...
Vertex AI: Successfully generated optimized response, length: 90
Kruthika AI: Generated contextual response: arre omg are you ok
Server Action: Generated enhanced response: arre omg are you ok
Server Action: New mood: naturally_responding
 POST /maya-chat 200 in 901ms
Server Action: Received message: ha bas tang tuti hai , fracture hua hai yrr
Kruthika AI: Analyzing conversation context...
Conversation context: normal_chat
Vertex AI: Starting optimized generateAIResponse...
User message length: 43
System prompt provided: true
Token Optimization: Selected gemini-2.0-flash-001 for conversation task
Token Optimization: Using normal config, max tokens: 300
Token Optimization: Input tokens optimized by -8 chars (0% cost reduction)
Vertex AI: Sending optimized request to model...
Vertex AI: Received response from model
Token Optimization: Cached response for message: ha bas tang tuti hai , fractur...
Vertex AI: Successfully generated optimized response, length: 76
Kruthika AI: Generated contextual response: omg yaar serious
Server Action: Generated enhanced response: omg yaar serious
Server Action: New mood: naturally_responding
 POST /maya-chat 200 in 631ms